# 计算机视觉 知识点速查手册

> 开卷考试专用 - 快速查找关键公式、概念和算法

---

## 目录

1. [基于特征的计算机视觉技术](#基于特征的计算机视觉技术)
   - [图像形成](#图像形成)
   - [视觉几何与摄像机标定](#视觉几何与摄像机标定)
   - [特征检测与匹配](#特征检测与匹配)
   - [立体视觉与双视图几何](#立体视觉与双视图几何)
   - [从运动恢复结构](#从运动恢复结构)

2. [基于神经网络的计算机视觉技术](#基于神经网络的计算机视觉技术)
   - [图像分类](#图像分类)
   - [反向传播](#反向传播)
   - [训练神经网络](#训练神经网络)
   - [典型CNN结构](#典型cnn结构)
   - [目标检测与分割](#目标检测与分割)
   - [GAN网络](#gan网络)

---

## 基于特征的计算机视觉技术

### 图像形成

#### 小孔成像模型
- 小孔成像：光线通过小孔在像平面上形成倒立实像

#### 透镜方程
$$\frac{1}{D'} + \frac{1}{D} = \frac{1}{f}$$

其中：
- $D$：物距（物体到透镜的距离）
- $D'$：像距（像到透镜的距离）
- $f$：焦距

#### 景深
- **景深**：对焦清晰的范围 $[D-\delta, D+\delta]$
- **光圈与景深**：
  - 光圈大 → 景深浅（$\delta$小）→ 背景虚化
  - 光圈小 → 景深深（$\delta$大）→ 前后都清晰

---

### 视觉几何与摄像机标定

#### 坐标系
1. **世界坐标系**：$P_w = (X_w, Y_w, Z_w)$
2. **相机坐标系**：$P_c = (X_c, Y_c, Z_c)$
3. **像平面坐标系**：$(x, y)$
4. **像素坐标系**：$(u, v)$

#### 相机内参（Intrinsic Parameters）

**1. 相机坐标系 → 像平面坐标系**
$$\begin{cases}
x = \frac{f X_c}{Z_c} \\
y = \frac{f Y_c}{Z_c}
\end{cases}$$

**2. 像平面坐标系 → 像素坐标系**
$$\begin{cases}
u = u_0 + k_u x \\
v = v_0 + k_v y
\end{cases}$$

**3. 综合：相机坐标系 → 像素坐标系**
$$\begin{cases}
u = u_0 + \frac{k_u f X_c}{Z_c} \\
v = v_0 + \frac{k_v f Y_c}{Z_c}
\end{cases}$$

**4. 矩阵形式（内参矩阵K）**
$$\lambda \begin{bmatrix} u \\ v \\ 1 \end{bmatrix} = \begin{bmatrix}
k_u f & 0 & u_0 \\
0 & k_v f & v_0 \\
0 & 0 & 1
\end{bmatrix} \begin{bmatrix} X_c \\ Y_c \\ Z_c \end{bmatrix} = K \begin{bmatrix} X_c \\ Y_c \\ Z_c \end{bmatrix}$$

**内参矩阵K包含**：
- $f$：焦距
- $k_u, k_v$：u、v方向的比例因子
- $u_0, v_0$：主点坐标（光轴与像平面的交点）

#### 相机外参（Extrinsic Parameters）

**世界坐标系 → 相机坐标系**
$$\begin{bmatrix} X_c \\ Y_c \\ Z_c \\ 1 \end{bmatrix} = \begin{bmatrix} R & T \\ 0 & 1 \end{bmatrix} \begin{bmatrix} X_w \\ Y_w \\ Z_w \\ 1 \end{bmatrix}$$

其中：
- $R$：3×3旋转矩阵
- $T$：3×1平移向量

#### 完整投影模型

**世界坐标系 → 像素坐标系**
$$\lambda \begin{bmatrix} u \\ v \\ 1 \end{bmatrix} = K[R|T] \begin{bmatrix} X_w \\ Y_w \\ Z_w \\ 1 \end{bmatrix}$$

其中 $P = K[R|T]$ 是投影矩阵。

#### 畸变

**1. 径向畸变**
- 由透镜缺陷引起
- 边缘部分扭曲更严重
- 可通过标定修正

**2. 透视畸变**
- 由相机位姿（$R, T$）引起
- 可通过调整相机位姿修正

#### 摄像机标定方法

**1. 直接求解**
- 使用标定板（已知$P_w$和对应的$(u,v)$）
- 每对点建立一个方程
- 6对点可求解投影矩阵$P$

**2. 几何误差优化**
- 最小化重投影误差
- 迭代优化得到最优解

**3. 多平面校准**
- 只需一个平面
- 不需要确定位姿
- 可计算内参和外参

#### 消失点和消失线

- **消失点**：现实中平行线在图像中的交点
- **消失线**：多个消失点所在的直线

---

### 特征检测与匹配

#### 好的特征应具备的特性

1. **可重复性**：图像变换后仍能找到
2. **显著性**：可区分
3. **高效性**：数量远少于像素数
4. **本地性**：基于局部区域计算

#### Harris角点检测

**1. 结构矩阵M**
$$M = \begin{bmatrix}
\sum I_x I_x & \sum I_x I_y \\
\sum I_x I_y & \sum I_y I_y
\end{bmatrix}$$

其中 $I_x, I_y$ 是图像在x、y方向的梯度。

**2. 响应函数R**
$$R = \det(M) - \alpha \cdot \text{trace}(M)^2 = \lambda_1 \lambda_2 - \alpha (\lambda_1 + \lambda_2)^2$$

其中 $\alpha$ 通常为0.04~0.06。

**3. 判断标准**
| $\lambda_1, \lambda_2$ | R | 是否为角点 |
|----------------------|---|-----------|
| 一个很大，一个很小 | R < 0 | 否（边缘） |
| 都很小 | R ≈ 0 | 否（平坦区域） |
| 都很大 | R > 0 | **是** |

**4. 检测流程**
1. 计算 $I_x, I_y$（可先高斯滤波）
2. 计算 $I_x^2, I_y^2, I_x I_y$
3. 高斯滤波得到区域内的 $\sum I_x I_x, \sum I_x I_y, \sum I_y I_y$
4. 计算响应函数 $R$
5. 非极大值抑制

#### SIFT（Scale-Invariant Feature Transform）

**1. 高斯-拉普拉斯算子（LoG）**
$$\sigma^2 \nabla^2 G(x, y, \sigma)$$

- 不同$\sigma$检测不同尺度的特征
- $\sigma$是尺度参数

**2. 高斯差分（DoG）**
$$DoG(x,y,\sigma,k) = G(x,y,k\sigma) - G(x,y,\sigma) \approx (k-1)\sigma^2 \nabla^2 G(x, y, \sigma)$$

- 用DoG近似尺度归一化的LoG，加速计算

**3. 关键点方向分配**

**梯度幅值和方向**：
$$m(x, y) = \sqrt{I_x^2 + I_y^2}$$
$$\theta(x, y) = \arctan \frac{I_y}{I_x}$$

- 生成方向直方图（36个bucket）
- 确定主方向（直方图最高峰）

**4. SIFT描述符**
- 16×16窗口，划分为4×4子区域（共16个）
- 每个子区域计算8方向直方图
- **最终：128维特征向量**（16×8）

#### 特征匹配

**方法**：
- 最近邻匹配
- **互最近邻法（Mutual Closest）**：效果最好

#### 特征对应（RANSAC）

**RANSAC流程**：
1. 随机选择4对特征点
2. 计算投影矩阵H
3. 计算内点数量（误差小于阈值）
4. 重复多次，选择内点最多的模型
5. 用所有内点重新估计H

---

### 立体视觉与双视图几何

#### 立体视觉（简单情况：平行相机）

**视差公式**：
$$Z_p = \frac{bf}{u_l - u_r}$$

其中：
- $b$：基线（两个相机间的距离）
- $f$：焦距
- $u_l - u_r$：视差（disparity）

**流程**：
1. 找到两张图像中的对应点
2. 计算视差 $u_l - u_r$
3. 估算距离 $Z_p$

#### 三角测量（一般情况）

**1. 直接求解**
- 使用SVD求解超定方程组
- 6个方程，3个未知数

**2. 最小化平方误差**
$$\min SSRE = ||p_1 - M_1 P||^2 + ||p_2 - M_2 P||^2$$

**3. 对baseline敏感**
- baseline太小 → 预测误差大
- baseline越大，精度越高

#### 双视图几何

**1. 基本概念**
- **极平面**：$p_L, C_L, C_R$三点确定的平面
- **极线**：极平面与像平面的交线
- **极点**：基线$C_L C_R$与像平面的交点

**2. 基础矩阵F（Fundamental Matrix）**
$$F = K_2^{-T} R [t]_X K_1^{-1}$$

**性质**：
- 3×3矩阵，秩为2
- ${x'}^T F x = 0$（对应点约束）

**3. 本质矩阵E（Essential Matrix）**
$$E = R [t]_X$$

**关系**：$F = K_2^{-T} E K_1^{-1}$

**4. 极线计算**
- 左图中点$p$，在右图中对应的极线：$Fp$

#### 8点法计算基础矩阵F

**步骤**：
1. 找到8对对应点
2. 每对点建立方程：${x'}^T F x = 0$
3. 8个方程求解F（9个未知数，令$f_{33}=1$）
4. SVD处理，使F的秩为2

#### 极线整流（Epipolar Rectification）

- 通过图像变换，使对应极线水平且对齐
- 便于快速寻找对应点

---

### 从运动恢复结构（SFM）

#### 流程

1. **若干图片 → 稀疏点云（SFM）**
2. **稀疏点云 → 稠密点云（MVS）**
3. **模型拟合**
4. **纹理贴图**

#### 两张图片 → 稀疏点云

**步骤**：
1. **特征点匹配**（SIFT）
2. **估算基础矩阵F**
   - 8点法
   - 几何误差：$\min \sum_j d(x_1^j, Fx_2^j)^2 + d(x_2^j, F^T x_1^j)^2$
   - RANSAC
3. **计算本质矩阵E**（如果内参已知）
   - $E = K_2^T F K_1$
   - 分解E得到$[R|t]$
4. **三角测量**：估算3D点坐标$P_w$

#### 光束法平差（Bundle Adjustment）

**优化目标**：
$$\min \sum_i \sum_j (\tilde{x}_i^j - K[R_i|t_i]X^j)^2$$

**未知参数**：
- $R_i, t_i$：每张图像的相机位姿
- $X^j$：每个3D点的坐标
- $K$：相机内参（可能未知）

**作用**：同时优化所有相机位姿和3D点位置，减少累积误差

---

## 基于神经网络的计算机视觉技术

### 图像分类

#### 线性分类器

**三种理解角度**：
1. **模板匹配**：每个类别一个模板
2. **几何视角**：每个类别一个决策边界
3. **代数视角**：$f(x) = Wx + b$

#### 损失函数

**1. Multiclass SVM Loss**
$$L_i = \sum_{j \neq y_i} \max(0, s_j - s_{y_i} + 1)$$

其中：
- $s_j$：第$j$类的得分
- $s_{y_i}$：真实类别的得分
- 如果 $s_{y_i} \geq s_j + 1$，损失为0

**2. 交叉熵损失**
$$L_i = -\log \frac{e^{s_{y_i}}}{\sum_j e^{s_j}} = -\log P(y_i|x_i)$$

#### 优化算法

**梯度下降**：
$$W \leftarrow W - \eta \nabla_W L$$

---

### 反向传播

#### 矩阵乘法求导

**前向传播**：
$$Y = XW$$

**反向传播**：
$$\begin{cases}
dW = X^T dY \\
dX = dY W^T
\end{cases}$$

**代码实现**：
```python
# 前向
Y = np.dot(X, W)

# 反向
dW = np.dot(X.T, dY)
dX = np.dot(dY, W.T)
```

---

### 训练神经网络

#### 激活函数

| 函数 | 公式 | 特点 |
|------|------|------|
| **Sigmoid** | $\sigma(x) = \frac{1}{1+e^{-x}}$ | 输出(0,1)，梯度消失 |
| **Tanh** | $\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$ | 输出(-1,1)，零中心 |
| **ReLU** | $\text{ReLU}(x) = \max(0, x)$ | 计算快，解决梯度消失 |
| **Leaky ReLU** | $\max(0.01x, x)$ | 解决ReLU死亡问题 |

#### 数据预处理

**1. 标准化**
$$X_{std} = \frac{X - \mu}{\sigma}$$

**2. PCA + Whitening**
- 去相关 + 归一化方差

**不同模型的预处理**：
| 模型 | 预处理 | 计算范围 |
|------|--------|---------|
| AlexNet | $X = X - \mu$ | 整张图片 |
| VGG | $X = X - \mu$ | 每个通道 |
| ResNet | $X_{std} = \frac{X - \mu}{\sigma}$ | 每个通道 |

#### 权重初始化

**1. 小随机值**
- 问题：激活值集中在0附近 → 梯度消失

**2. Xavier初始化**
- 适用于tanh激活函数
- 根据输入单元数计算方差

**3. Kaiming初始化（He初始化）**
- 适用于ReLU激活函数
- 何恺明等人提出

#### Batch Normalization

**作用**：
- 直接调整输入值，使其满足标准正态分布
- 减少对初始化的依赖
- 加速训练，提高稳定性

#### 优化算法

**算法演进**：
```
SGD → Momentum / AdaGrad
     ↓
Momentum + RMSProp → Adam → AdamW
```

**关键算法**：
- **SGD**：$w \leftarrow w - \eta \nabla_w L$
- **Momentum**：引入动量项
- **AdaGrad**：自适应学习率
- **RMSProp**：改进AdaGrad
- **Adam**：结合Momentum和RMSProp

#### 学习率调度

**常见策略**：
- 固定衰减
- 指数衰减
- 余弦退火
- Warmup

#### 正则化

**1. 权重衰减（L1/L2正则）**
$$L_{total} = L_{data} + \lambda ||W||^2$$

**2. Dropout**
- 训练时随机丢弃部分神经元
- 测试时使用所有神经元（期望值）

**3. 通用模式**
- 训练时引入随机性
- 测试时求期望，消除随机性
- 包括：数据增广、DropConnect、Stochastic Depth等

---

### 典型CNN结构

#### 卷积层优势

**参数量对比**（1000×1000图像，10^6个隐藏神经元）：
| 结构 | 参数量 |
|------|--------|
| 全连接层 | $10^{12}$ |
| 局部感受野 | $10^8$ |
| 局部感受野 + 权值共享 | $10^2$ |
| 卷积层（100个卷积核） | $10^4$ |

**关键技术**：
- **局部感受野**：每个神经元只连接局部区域
- **权值共享**：同一卷积核在不同位置共享参数
- **池化**：降低空间分辨率，增加感受野

#### AlexNet
- 8层网络
- ILSVRC 2012冠军
- 首次使用ReLU、Dropout

#### VGGNet

**核心思想**：堆积小卷积核

**感受野**：
- 2个3×3卷积 ≈ 1个5×5卷积
- 3个3×3卷积 ≈ 1个7×7卷积

**参数量**（输入输出通道均为C）：
| 结构 | 参数量 | 非线性 |
|------|--------|--------|
| 1层7×7 | $49C^2$ | 1次ReLU |
| 3层3×3 | $27C^2$ | 3次ReLU |

**优势**：参数量更少，非线性更强

#### GoogLeNet

**Inception块**：
- 多尺度卷积并行
- 使用1×1卷积降维（减少参数量）

**Inception v1 vs v2**：
- v1：直接多尺度卷积，参数量大
- v2：先用1×1降维，再卷积，参数量减少

**辅助分类器**：
- 在中间层添加分类器
- 缓解梯度消失

#### ResNet

**残差连接**：
$$y = F(x) + x$$

**优势**：
- 解决梯度消失问题
- 可以训练更深的网络（152层）
- ILSVRC 2015冠军

#### 第一层卷积核尺寸

| 模型 | 第一层卷积核 | 说明 |
|------|------------|------|
| LeNet | 5×5 | 32×32图像 |
| AlexNet | 11×11 | 224×224图像 |
| ZFNet | 7×7 | 调整超参 |
| VGG | 3×3（堆积） | 小卷积核 |
| GoogLeNet | 7×7 | |
| ResNet | 7×7 | |

**结论**：第一层可用7×7或5×5，后续层用3×3堆积

---

### 目标检测与分割

#### 语义分割

**简单方案**：
- 每个像素一个分类器
- 计算量大

**FCN（Fully Convolutional Networks）**：
- 先下采样（卷积+池化）
- 再上采样（转置卷积）
- 减少计算量

**上采样方法**：
1. 简单上采样（最近邻/双线性）
2. 转置卷积（可学习）

#### 目标检测

**单目标检测**：
- 多任务学习
  - 分类：预测类别
  - 回归：预测边界框坐标

**多目标检测 - R-CNN系列**：

**1. R-CNN**
- 选择性搜索生成2000个候选区域
- 每个区域变形后通过CNN
- **耗时**：49s/图

**2. Fast R-CNN**
- 整图通过CNN得到特征图
- 候选区域投影到特征图（RoI）
- 再通过网络做多任务学习
- **耗时**：2.3s/图

**3. Faster R-CNN**
- 用区域提议网络（RPN）替代选择性搜索
- 端到端训练
- **耗时**：0.2s/图

**改进思路**：
- R-CNN：2000次CNN前向计算 → Fast R-CNN：1次CNN前向计算
- Fast R-CNN：选择性搜索耗时 → Faster R-CNN：RPN替代

#### 实例分割

**Mask R-CNN**：
- 在Faster R-CNN基础上
- 添加掩码预测分支（小型FCN）
- 像素级预测

---

### GAN网络

#### 基本结构

**1. 生成器（Generator）**
- 类似VAE的decoder
- 输入：随机噪声$z$
- 输出：生成图像$G(z)$

**2. 判别器（Discriminator）**
- CNN分类器
- 输入：图像
- 输出：真/假概率$D(x)$

#### 训练流程

**1. 生成器训练**
- 固定判别器
- 损失函数：
$$J_G = -\frac{1}{m} \sum_{i=1}^m \log D(G(z_i))$$
- 目标：$D(G(z_i))$ 接近1

**2. 判别器训练**
- 固定生成器
- 损失函数：
$$J_D = -\frac{1}{m} \sum_{i=1}^m \log D(x_i) - \frac{1}{m} \sum_{i=1}^m \log(1-D(G(z_i)))$$
- 目标：$D(x_i)$ 接近1，$D(G(z_i))$ 接近0

#### 全局最优解

**纳什均衡**：
- 当 $P_{gene} = P_{data}$ 时达到最优
- 此时判别器准确率 = 50%
- 生成器完全恢复数据分布

**问题**：GAN训练困难，难以收敛

---

## 常用公式速查

### 相机投影
$$\lambda \begin{bmatrix} u \\ v \\ 1 \end{bmatrix} = K[R|T] \begin{bmatrix} X_w \\ Y_w \\ Z_w \\ 1 \end{bmatrix}$$

### 内参矩阵
$$K = \begin{bmatrix}
k_u f & 0 & u_0 \\
0 & k_v f & v_0 \\
0 & 0 & 1
\end{bmatrix}$$

### 外参矩阵
$$\begin{bmatrix} X_c \\ Y_c \\ Z_c \\ 1 \end{bmatrix} = \begin{bmatrix} R & T \\ 0 & 1 \end{bmatrix} \begin{bmatrix} X_w \\ Y_w \\ Z_w \\ 1 \end{bmatrix}$$

### 视差公式
$$Z_p = \frac{bf}{u_l - u_r}$$

### 基础矩阵
$$F = K_2^{-T} R [t]_X K_1^{-1}$$

### 本质矩阵
$$E = R [t]_X$$

### 对应点约束
$${x'}^T F x = 0$$

### Harris响应函数
$$R = \lambda_1 \lambda_2 - \alpha (\lambda_1 + \lambda_2)^2$$

### 梯度幅值和方向
$$m(x,y) = \sqrt{I_x^2 + I_y^2}$$
$$\theta(x,y) = \arctan \frac{I_y}{I_x}$$

### 反向传播
$$Y = XW \Rightarrow \begin{cases} dW = X^T dY \\ dX = dY W^T \end{cases}$$

### 残差连接
$$y = F(x) + x$$

---

## 关键概念速查

### 图像形成
- **小孔成像**：光线通过小孔形成倒立实像
- **透镜方程**：$\frac{1}{D'} + \frac{1}{D} = \frac{1}{f}$
- **景深**：对焦清晰的范围，与光圈大小相关

### 相机参数
- **内参**：$f, k_u, k_v, u_0, v_0$（相机固有参数）
- **外参**：$R, T$（相机位姿）
- **畸变**：径向畸变（透镜缺陷）、透视畸变（位姿问题）

### 特征检测
- **Harris角点**：$R > 0$ 且两个特征值都大
- **SIFT**：128维描述符，具有尺度、旋转不变性
- **RANSAC**：鲁棒估计，处理外点

### 立体视觉
- **视差**：$u_l - u_r$，用于计算深度
- **三角测量**：从两个视角恢复3D点
- **极线**：对应点所在的直线

### 神经网络训练
- **激活函数**：ReLU最常用
- **Batch Norm**：归一化输入，加速训练
- **优化算法**：Adam最常用
- **正则化**：Dropout、权重衰减

### CNN结构
- **局部感受野 + 权值共享**：大幅减少参数量
- **池化**：降低分辨率，增加感受野
- **残差连接**：解决梯度消失，训练更深网络

### 目标检测
- **R-CNN**：候选区域 + CNN分类
- **Fast R-CNN**：共享特征图
- **Faster R-CNN**：RPN生成候选区域

---

**祝考试顺利！**

